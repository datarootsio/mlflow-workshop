{
  "nbformat": 4,
  "nbformat_minor": 4,
  "metadata": {},
  "cells": [
    {
      "metadata": {},
      "source": [
        "# Heart Disease Prediction \n",
        "\n",
        "In this example we'll work with the famous \"UCI Heart Disease\" dataset. This dataset contains a set of attributes related to patient potentially affected by a cardiovascular disease (CVD). CVD is one of the biggest causes of mortality but it's estimated that up to 90% of CVD may be preventable, an early diagnosis could be essential in most cases and AI can achieve this goal."
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "## Binary Classification\n",
        "Classification is one of the most common unsupervised learning tasks. In a lot of ML applications we need a model that is able to distinguish between two classes, therefore a binary classifier.\n",
        "With the help of the most common ML libraries (like sklearn) it's really easy to train a binary classifier, however evaluating the performance it's not so easy. We will explore model training/evaluating and concepts like Confusion Matrix, Precision, Recall etc ..."
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "# Get the data\n",
        "data = pd.read_csv('../data/heart.csv')"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "# Let's check the data we have\n",
        "data.head()"
      ],
      "cell_type": "code",
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>cp</th>\n",
              "      <th>trestbps</th>\n",
              "      <th>chol</th>\n",
              "      <th>fbs</th>\n",
              "      <th>restecg</th>\n",
              "      <th>thalach</th>\n",
              "      <th>exang</th>\n",
              "      <th>oldpeak</th>\n",
              "      <th>slope</th>\n",
              "      <th>ca</th>\n",
              "      <th>thal</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>63</td>\n",
              "      <td>Male</td>\n",
              "      <td>asymptomatic</td>\n",
              "      <td>NaN</td>\n",
              "      <td>233.0</td>\n",
              "      <td>True</td>\n",
              "      <td>normal</td>\n",
              "      <td>150</td>\n",
              "      <td>No</td>\n",
              "      <td>2.3</td>\n",
              "      <td>upsloping</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>37</td>\n",
              "      <td>Male</td>\n",
              "      <td>non-anginal pain</td>\n",
              "      <td>130.0</td>\n",
              "      <td>250.0</td>\n",
              "      <td>False</td>\n",
              "      <td>having ST-T wave abnormality</td>\n",
              "      <td>187</td>\n",
              "      <td>No</td>\n",
              "      <td>3.5</td>\n",
              "      <td>upsloping</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>41</td>\n",
              "      <td>Female</td>\n",
              "      <td>atypical angina</td>\n",
              "      <td>130.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "      <td>normal</td>\n",
              "      <td>172</td>\n",
              "      <td>No</td>\n",
              "      <td>1.4</td>\n",
              "      <td>downsloping</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>56</td>\n",
              "      <td>Male</td>\n",
              "      <td>atypical angina</td>\n",
              "      <td>120.0</td>\n",
              "      <td>236.0</td>\n",
              "      <td>False</td>\n",
              "      <td>having ST-T wave abnormality</td>\n",
              "      <td>178</td>\n",
              "      <td>No</td>\n",
              "      <td>0.8</td>\n",
              "      <td>downsloping</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>57</td>\n",
              "      <td>Female</td>\n",
              "      <td>typical angina</td>\n",
              "      <td>120.0</td>\n",
              "      <td>354.0</td>\n",
              "      <td>False</td>\n",
              "      <td>having ST-T wave abnormality</td>\n",
              "      <td>163</td>\n",
              "      <td>Yes</td>\n",
              "      <td>0.6</td>\n",
              "      <td>downsloping</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   age     sex                cp  trestbps   chol    fbs  \\\n",
              "0   63    Male      asymptomatic       NaN  233.0   True   \n",
              "1   37    Male  non-anginal pain     130.0  250.0  False   \n",
              "2   41  Female   atypical angina     130.0    NaN  False   \n",
              "3   56    Male   atypical angina     120.0  236.0  False   \n",
              "4   57  Female    typical angina     120.0  354.0  False   \n",
              "\n",
              "                        restecg  thalach exang  oldpeak        slope  ca  \\\n",
              "0                        normal      150    No      2.3    upsloping   0   \n",
              "1  having ST-T wave abnormality      187    No      3.5    upsloping   0   \n",
              "2                        normal      172    No      1.4  downsloping   0   \n",
              "3  having ST-T wave abnormality      178    No      0.8  downsloping   0   \n",
              "4  having ST-T wave abnormality      163   Yes      0.6  downsloping   0   \n",
              "\n",
              "   thal  target  \n",
              "0     1       1  \n",
              "1     2       1  \n",
              "2     2       1  \n",
              "3     2       1  \n",
              "4     2       1  "
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "Attribute meaning:\n",
        "\n",
        "1. age: age in years\n",
        "2. sex: sex (1 = male; 0 = female)\n",
        "3.  cp: chest pain type\n",
        "    * Value 1: typical angina\n",
        "    * Value 2: atypical angina\n",
        "    * Value 3: non-anginal pain\n",
        "    * Value 4: asymptomatic\n",
        "4. trestbps: resting blood pressure (in mm Hg on admission to the hospital)\n",
        "5. chol: serum cholestoral in mg/dl\n",
        "6. fbs: (fasting blood sugar > 120 mg/dl) (1 = true; 0 = false)\n",
        "7. restecg: resting electrocardiographic results\n",
        "    * Value 0: normal\n",
        "    * Value 1: having ST-T wave abnormality (T wave inversions and/or ST elevation or depression of > 0.05 mV)\n",
        "    * Value 2: showing probable or definite left ventricular hypertrophy by Estes' criteria\n",
        "8. thalach: maximum heart rate achieved\n",
        "9. exang: exercise induced angina (1 = yes; 0 = no)\n",
        "10. oldpeak = ST depression induced by exercise relative to rest\n",
        "11. slope: the slope of the peak exercise ST segment\n",
        "    * Value 1: upsloping\n",
        "    * Value 2: flat\n",
        "    * Value 3: downsloping\n",
        "12. ca: number of major vessels (0-3) colored by flourosopy\n",
        "13. thal: 3 = normal; 6 = fixed defect; 7 = reversable defect\n",
        "\n"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "list(data.select_dtypes(include=['object']).columns)"
      ],
      "cell_type": "code",
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['sex', 'cp', 'restecg', 'exang', 'slope']"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "list(data.select_dtypes(include=['number']).columns)"
      ],
      "cell_type": "code",
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['age', 'trestbps', 'chol', 'thalach', 'oldpeak', 'ca', 'thal', 'target']"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "data.info()"
      ],
      "cell_type": "code",
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 303 entries, 0 to 302\n",
            "Data columns (total 14 columns):\n",
            " #   Column    Non-Null Count  Dtype  \n",
            "---  ------    --------------  -----  \n",
            " 0   age       303 non-null    int64  \n",
            " 1   sex       303 non-null    object \n",
            " 2   cp        303 non-null    object \n",
            " 3   trestbps  258 non-null    float64\n",
            " 4   chol      273 non-null    float64\n",
            " 5   fbs       303 non-null    bool   \n",
            " 6   restecg   303 non-null    object \n",
            " 7   thalach   303 non-null    int64  \n",
            " 8   exang     303 non-null    object \n",
            " 9   oldpeak   303 non-null    float64\n",
            " 10  slope     303 non-null    object \n",
            " 11  ca        303 non-null    int64  \n",
            " 12  thal      303 non-null    int64  \n",
            " 13  target    303 non-null    int64  \n",
            "dtypes: bool(1), float64(3), int64(5), object(5)\n",
            "memory usage: 31.2+ KB\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "303 records, some null values"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "data.describe()"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "The mean age is the 54 years, adults are more likely than younger people to suffer from cardiovascular disease."
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "# Let's check the target value\n",
        "data.target.value_counts()"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "The dataset is balanced. However, this is the most boring dataset ever XD no missing values, no labels to encode, balanced dataset ... Let's change some columns just for fun "
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "# Add some labels\n",
        "data.sex = data.sex.replace([1, 0], [\"Male\", \"Female\"])\n",
        "data.cp = data.cp.replace([0, 1, 2, 3], [\"typical angina\", \"atypical angina\", \"non-anginal pain\", \"asymptomatic\"])\n",
        "data.fbs = data.fbs.replace([0, 1], [\"False\", \"True\"])\n",
        "data.restecg = data.restecg.replace([0, 1, 2], [\"normal\", \"having ST-T wave abnormality\", \"showing probable or definite left ventricular hypertrophy by Estes' criteria\"])\n",
        "data.exang = data.exang.replace([0, 1], [\"No\", \"Yes\"])\n",
        "data.slope = data.slope.replace([0, 1, 2], [\"upsloping\", \"flat\", \"downsloping\"])\n",
        "\n",
        "# Add missing values\n",
        "data.chol = data.chol.sample(frac=0.9)\n",
        "data.trestbps = data.trestbps.sample(frac=0.85)\n",
        "\n",
        "data.head()"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "data.info()"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "A little bit dirty dataset <3"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "data.to_csv(\"../data/heart.csv\", index=False)"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "# test and train split\n",
        "\n",
        "train_set, test_set = train_test_split(data, test_size=0.2, random_state=5)"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "# Let's plot the numerical histogram\n",
        "train_set.hist(bins=50, figsize=(20, 15))"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "The feature have different scale, it's a good idea to perform standard scaling"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "# Create a pipeline to encode categorical variable using one hot encoding, insert missing values using the median strategy and scale the value \n",
        "cat_attr = [\"sex\", \"cp\", \"fbs\", \"restecg\", \"exang\", \"slope\"]\n",
        "num_attr = [\"age\", \"trestbps\", \"chol\", \"thalach\", \"oldpeak\", \"ca\", \"thal\"]\n",
        "\n",
        "num_pipeline = Pipeline([\n",
        "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
        "    (\"std_scaler\", StandardScaler())\n",
        "])\n",
        "\n",
        "full_pipeline = ColumnTransformer([\n",
        "    (\"num\", num_pipeline, num_attr),\n",
        "    (\"cat\", OneHotEncoder(), cat_attr)\n",
        "])"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "x_train = train_set.drop(\"target\", axis=1)\n",
        "y_train = train_set.target"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "x_train_pr = full_pipeline.fit_transform(x_train)"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "Let's train a simple binary classifier, a Stochastic Gradient Descent classifier (SGD)"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "from sklearn.linear_model import SGDClassifier\n",
        "\n",
        "sgd_clf = SGDClassifier(random_state=40)"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "Usually a good way to evaluate a model is to use cross-validation"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "scores = cross_val_score(sgd_clf, x_train_pr, y_train, cv=3, scoring=\"accuracy\")\n",
        "scores.mean()"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "It's not a great value. I think it's a better idea to evaluate our model using other tools like the confusion matrix"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "# It's like cross-validation but it returns the predictions\n",
        "from sklearn.model_selection import cross_val_predict\n",
        "\n",
        "preds = cross_val_predict(sgd_clf, x_train_pr, y_train, cv=3)"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "# Now we can plot the confusion matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "confusion_matrix(y_train, preds)"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "Let's see precison and recall score"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "from sklearn.metrics import precision_score, recall_score\n",
        "\n",
        "precision_score(y_train, preds)"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "recall_score(y_train, preds)"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "# The f1 score combines precision and recall\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "f1_score(y_train, preds)"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "# Another measure is the roc aud score\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "roc_auc_score(y_train, preds)"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "I think that it's a better idea to try more powerfull models like a RandomForestClassifier"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "forest_clf = RandomForestClassifier(random_state=42)\n",
        "forest_preds = cross_val_predict(forest_clf, x_train_pr, y_train, cv=3)"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "confusion_matrix(y_train, forest_preds)"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "precision_score(y_train, forest_preds)"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "recall_score(y_train, forest_preds)"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "f1_score(y_train, forest_preds)"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "Slightly better thant the SGD classifier. Let's train the random forest classifier on the full dataset and evaluate on the test set"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "forest_clf.fit(x_train_pr, y_train)"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "x_test = test_set.drop(\"target\", axis=1)\n",
        "y_test = test_set.target"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "x_test_pr = full_pipeline.transform(x_test)\n",
        "\n",
        "final_preds = forest_clf.predict(x_test_pr)"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "precision_score(y_test, final_preds)"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "recall_score(y_test, final_preds)"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "f1_score(y_test, final_preds)"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "This was a simple example on how to evaluate a classifier, however the result is good! Cross-validation is a good method for model evaluation, but since we split our dataset in 3 folds the model had few data for achieve good performances. With the full dataset we reach a good result!"
      ],
      "cell_type": "markdown"
    }
  ]
}